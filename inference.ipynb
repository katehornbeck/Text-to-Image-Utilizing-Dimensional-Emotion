{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b628183-a207-4c93-a847-d2e8c747210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "import torch\n",
    "\n",
    "from src.vad_trainer import SingleDatasetTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e10bb09-0a96-4f5a-9522-c8c7482c161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: AMD Radeon RX 7800 XT\n",
      "SingleDatasetTrainer created\n",
      "Build dataset for train/valid/test\n",
      "Building datasets\n",
      "Loading data into EmotionDataset for emobank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2690: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An empty sentence example encountered. (after preprocessing): skipping... ( train set )\n",
      "An empty sentence example encountered. (after preprocessing): skipping... ( valid set )\n",
      "Building dataloaders\n",
      "Dataset Loaded: emobank with labels: ['V', 'A', 'D']\n",
      "build/load models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loading Info: {'missing_keys': ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight'], 'unexpected_keys': ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight'], 'mismatched_keys': [], 'error_msgs': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model from: data/private/try-2/ckpt/trained/emobank-vad-regression-7560-30.ckpt\n",
      "Loading Model from: data/private/try-2/ckpt/trained/emobank-vad-regression-7560-30.ckpt ...Finished.\n"
     ]
    }
   ],
   "source": [
    "config_filename = \"config-inference.txt\"\n",
    "\n",
    "#Getting configurations\n",
    "with open(config_filename) as config_file:\n",
    "    args = json.load(config_file)\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "sdt = SingleDatasetTrainer(args)\n",
    "sdt.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99c3d2d-20ce-4479-b677-293662ea73bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids tensor([[    0,  7516,   127, 21863,   328,    91,  1850,   328,    38,   115,\n",
      "            28,     5, 30947,   621,    11,     5,   232,   328,     2]],\n",
      "       device='cuda:0')\n",
      "lm_logits: tensor([[[-0.7747, -0.2140,  0.3580,  ..., -0.8444,  0.4937,  0.2890],\n",
      "         [-1.0347, -0.2380,  0.2211,  ..., -0.9891,  0.5348,  0.5793],\n",
      "         [-0.4601, -0.3373,  0.3970,  ..., -1.2755,  0.2926,  0.8019],\n",
      "         ...,\n",
      "         [-1.2005, -0.5172,  0.3406,  ..., -0.8101,  0.5326,  0.4300],\n",
      "         [-0.7437, -0.4177,  0.2000,  ..., -0.9499,  0.5123,  0.6339],\n",
      "         [-0.7206, -0.3189,  0.4094,  ..., -0.8825,  0.5042,  0.1890]]],\n",
      "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n",
      "cls_logits: tensor([[3.0718, 3.6294, 3.2361]], device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:296.)\n",
      "  return F.linear(input, self.weight, self.bias)\n",
      "/home/kate/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:370: UserWarning: Flash attention support on Navi31 GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:234.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "/home/kate/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:370: UserWarning: Memory Efficient attention on Navi31 GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:278.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "sdt.inference(\"Oh my goodness! He proposed! I could be the happiest person in the world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92e6076-99f4-439d-a6aa-cacfbf4f8600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids tensor([[  0, 100, 109,  45, 101, 123,   2]], device='cuda:0')\n",
      "lm_logits: tensor([[[-0.7295, -0.2362,  0.3991,  ..., -0.8853,  0.5151,  0.2558],\n",
      "         [-0.6266, -0.2511,  0.3869,  ..., -1.0261,  0.5913,  0.3516],\n",
      "         [-0.7422, -0.3846,  0.4614,  ..., -1.0089,  0.5678,  0.3488],\n",
      "         ...,\n",
      "         [-0.6857, -0.3221,  0.3708,  ..., -1.1352,  0.5719,  0.4288],\n",
      "         [-0.7211, -0.1666,  0.4352,  ..., -0.9381,  0.5863,  0.3846],\n",
      "         [-0.6792, -0.2929,  0.4321,  ..., -0.9080,  0.5156,  0.1761]]],\n",
      "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n",
      "cls_logits: tensor([[3.1597, 3.5706, 3.2086]], device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sdt.inference(\"I do not like him\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359f765-4c21-4cac-8575-d35d561a02c8",
   "metadata": {},
   "source": [
    "# TESTING AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d237c9d3-22ae-4d5a-88a4-5e118a2110c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.models.gigagan import GigaGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1cd8df-7d64-4ba7-8dfa-eff03e3a7374",
   "metadata": {},
   "outputs": [
    {
     "ename": "BeartypeCallHintForwardRefException",
     "evalue": "Forward reference \"BaseGenerator\" unimportable from module \"src.models.gigagan.gigagan_pytorch\".",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBeartypeCallHintForwardRefException\u001b[39m       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m text_encoder = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m      2\u001b[39m     dim = \u001b[32m64\u001b[39m,\n\u001b[32m      3\u001b[39m     depth = \u001b[32m120\u001b[39m,\n\u001b[32m      4\u001b[39m     vad_model_path = \u001b[33m\"\u001b[39m\u001b[33m/home/kate/grad_school/GenAI/final/data/private/try-2/ckpt/trained/emobank-vad-regression-7560-30.ckpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     vad_config_path = \u001b[33m\"\u001b[39m\u001b[33m/home/kate/grad_school/GenAI/final/config-inference.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m gan = \u001b[43mGigaGAN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdim_capacity\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstyle_network\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdim_max\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_skip_layers_excite\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_encoder\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_encoder\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdim_capacity\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdim_max\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_skip_layers_excite\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_encoder\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_encoder\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<@beartype(src.models.gigagan.gigagan_pytorch.GigaGAN.__init__) at 0x7abcd7ec7560>:24\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(__beartype_object_134952055825728, __beartype_get_violation, __beartype_conf, __beartype_object_134951495177600, __beartype_object_134951500709632, __beartype_object_134962639566976, __beartype_object_134951495176896, __beartype_object_134951495176512, __beartype_check_meta, __beartype_func, *args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/beartype/_check/forward/reference/fwdrefmeta.py:295\u001b[39m, in \u001b[36mBeartypeForwardRefMeta.__instancecheck__\u001b[39m\u001b[34m(cls, obj)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03m:data:`True` only if the passed object is an instance of the external\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[33;03mclass referenced by the passed **forward reference subclass** (i.e.,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    290\u001b[39m \u001b[33;03m    class referenced by this forward reference subclass.\u001b[39;00m\n\u001b[32m    291\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Return true only if this forward reference subclass insists that this\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# object satisfies the external class referenced by this subclass.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__is_instance_beartype__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/beartype/_check/forward/reference/fwdrefabc.py:112\u001b[39m, in \u001b[36mBeartypeForwardRefABC.__is_instance_beartype__\u001b[39m\u001b[34m(cls, obj)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[33;03m:data:`True` only if the passed object is an instance of the external\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[33;03mclass referred to by this forward reference.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    class referred to by this forward reference subclass.\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# # Resolve the external class referred to by this forward reference and\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# # permanently store that class in the \"__type_beartype__\" variable.\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# cls.__beartype_resolve_type__()\u001b[39;00m\n\u001b[32m    109\u001b[39m \n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# Return true only if this object is an instance of the external class\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# referenced by this forward reference.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__type_beartype__\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/beartype/_check/forward/reference/fwdrefmeta.py:451\u001b[39m, in \u001b[36mBeartypeForwardRefMeta.__type_beartype__\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m    448\u001b[39m EXCEPTION_PREFIX = \u001b[33m'\u001b[39m\u001b[33mForward reference \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# Forward referent dynamically imported from this module.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m referent = \u001b[43mimport_module_attr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__name_beartype__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__scope_name_beartype__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexception_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEXCEPTION_CLS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexception_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEXCEPTION_PREFIX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[38;5;66;03m# If this referent is this forward reference subclass, then this\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;66;03m# subclass circularly proxies itself. Since allowing this edge case\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[38;5;66;03m# would openly invite infinite recursion, we detect this edge case\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;66;03m# and instead raise a human-readable exception.\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m referent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/beartype/_util/module/utilmodimport.py:295\u001b[39m, in \u001b[36mimport_module_attr\u001b[39m\u001b[34m(attr_name, module_name, exception_cls, exception_prefix)\u001b[39m\n\u001b[32m    291\u001b[39m             exception_message += (\n\u001b[32m    292\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m from unimportable module \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# Raise this exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_cls(exception_message)\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# Else, this module declares this attribute.\u001b[39;00m\n\u001b[32m    297\u001b[39m \n\u001b[32m    298\u001b[39m \u001b[38;5;66;03m# Else, return this attribute.\u001b[39;00m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module_attr\n",
      "\u001b[31mBeartypeCallHintForwardRefException\u001b[39m: Forward reference \"BaseGenerator\" unimportable from module \"src.models.gigagan.gigagan_pytorch\"."
     ]
    }
   ],
   "source": [
    "text_encoder = dict(\n",
    "    dim = 64,\n",
    "    depth = 120,\n",
    "    vad_model_path = \"/home/kate/grad_school/GenAI/final/data/private/try-2/ckpt/trained/emobank-vad-regression-7560-30.ckpt\",\n",
    "    vad_config_path = \"/home/kate/grad_school/GenAI/final/config-inference.txt\"\n",
    ")\n",
    "\n",
    "gan = GigaGAN(\n",
    "    generator = dict(\n",
    "        dim_capacity = 8,\n",
    "        style_network = dict(\n",
    "            dim = 64,\n",
    "            depth = 4\n",
    "        ),\n",
    "        image_size = 256,\n",
    "        dim_max = 512,\n",
    "        num_skip_layers_excite = 4,\n",
    "        text_encoder = text_encoder\n",
    "    ),\n",
    "    discriminator = dict(\n",
    "        dim_capacity = 16,\n",
    "        dim_max = 512,\n",
    "        image_size = 256,\n",
    "        num_skip_layers_excite = 4,\n",
    "        text_encoder = text_encoder\n",
    "    ),\n",
    "    amp = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8c1f22-01d8-4ea2-92f8-f4b295801d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/grad_school/GenAI/final/final-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.models.gigagan import ImageDataset\n",
    "\n",
    "dataset = ImageDataset(\n",
    "    folder = '../datasets/laion2B-en-aesthetic',\n",
    "    image_size = 256\n",
    ")\n",
    "dataloader = dataset.get_dataloader(batch_size = 1)\n",
    "gan.set_dataloader(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001142d9-5939-4e50-92b0-49216db0f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan(steps=100, grad_accum_every = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07279c6f-53d6-4189-a01b-4306bc584117",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = gan.generate(batch_size = 4)\n",
    "print(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "final-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
